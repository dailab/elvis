{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import math\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resolution 1 hour\n",
    "dates = [\n",
    "    datetime.datetime(2020, 10, 1, 10, 0),\n",
    "    datetime.datetime(2020, 10, 1, 11, 0),\n",
    "    datetime.datetime(2020, 10, 1, 12, 0),\n",
    "    datetime.datetime(2020, 10, 1, 13, 0),\n",
    "    datetime.datetime(2020, 10, 1, 15, 0),\n",
    "    datetime.datetime(2020, 10, 1, 18, 0),\n",
    "    datetime.datetime(2020, 10, 1, 20, 0),\n",
    "    datetime.datetime(2020, 10, 1, 21, 0),\n",
    "]\n",
    "\n",
    "values = [\n",
    "    0.312, 0.121, 0.1372, 0.73221, 0.17, 0.18281, 0.12, 0.1727\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resolution 1 hour, swapped\n",
    "dates = [\n",
    "    datetime.datetime(2020, 10, 1, 21, 0),\n",
    "    datetime.datetime(2020, 10, 1, 22, 0),\n",
    "    datetime.datetime(2020, 10, 1, 23, 0),\n",
    "    datetime.datetime(2020, 10, 2,  7, 0),\n",
    "    datetime.datetime(2020, 10, 2,  8, 0),\n",
    "    datetime.datetime(2020, 10, 2, 10, 0),\n",
    "    datetime.datetime(2020, 10, 2, 12, 0),\n",
    "    datetime.datetime(2020, 10, 2, 15, 0),\n",
    "]\n",
    "\n",
    "values = [\n",
    "    0.312, 0.121, 0.1372, 0.73221, 0.17, 0.18281, 0.12, 0.1727\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resolution 1 minute \n",
    "dates = [\n",
    "    datetime.datetime(2020, 10, 1, 10, 10, 0),\n",
    "    datetime.datetime(2020, 10, 1, 10, 11, 0),\n",
    "    datetime.datetime(2020, 10, 1, 10, 12, 0),\n",
    "    datetime.datetime(2020, 10, 1, 10, 13, 0),\n",
    "    datetime.datetime(2020, 10, 1, 10, 15, 0),\n",
    "    datetime.datetime(2020, 10, 1, 10, 18, 0),\n",
    "    datetime.datetime(2020, 10, 1, 10, 20, 0),\n",
    "    datetime.datetime(2020, 10, 1, 10, 21, 0),\n",
    "]\n",
    "\n",
    "values = [\n",
    "    0.312, 0.121, 0.1372, 0.73221, 0.17, 0.18281, 0.12, 0.1727\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resolution 10 seconds \n",
    "dates = [\n",
    "    datetime.datetime(2020, 10, 1, 10, 10, 0),\n",
    "    datetime.datetime(2020, 10, 1, 10, 10, 10),\n",
    "    datetime.datetime(2020, 10, 1, 10, 10, 20),\n",
    "    datetime.datetime(2020, 10, 1, 10, 10, 30),\n",
    "    datetime.datetime(2020, 10, 1, 10, 10, 50),\n",
    "    datetime.datetime(2020, 10, 1, 10, 11, 20),\n",
    "    datetime.datetime(2020, 10, 1, 10, 11, 40),\n",
    "    datetime.datetime(2020, 10, 1, 10, 12, 10),\n",
    "]\n",
    "\n",
    "values = [\n",
    "    0.312, 0.121, 0.1372, 0.73221, 0.17, 0.18281, 0.12, 0.1727\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rnd_dataset(start, end, resolution, min_step, max_step):\n",
    "    dates = []\n",
    "    values = []\n",
    "\n",
    "    curr = start\n",
    "    first = True\n",
    "\n",
    "    while curr < end:\n",
    "        dates.append(curr)\n",
    "        values.append(random.random())\n",
    "\n",
    "        if first:\n",
    "            step = 1\n",
    "            first = False\n",
    "        else:\n",
    "            step = random.randint(min_step, max_step)\n",
    "\n",
    "        curr += resolution * step\n",
    "\n",
    "    return (dates, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dates, values = generate_rnd_dataset(datetime.datetime(2020, 1, 1, 0, 0, 0),\n",
    "                                     datetime.datetime(2022, 1, 1, 0, 0, 0),\n",
    "                                     datetime.timedelta(hours=1),\n",
    "                                     1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(file, date_col, value_col, is_cumulative):\n",
    "    dates = []\n",
    "    values = []\n",
    "    with open(file, \"r\") as f:\n",
    "        reader = csv.reader(f, delimiter=\",\")\n",
    "        value_col_idx = None\n",
    "        date_col_idx = None\n",
    "\n",
    "        for row in reader:\n",
    "            if value_col_idx is None:\n",
    "                for i in range(0, len(row)):\n",
    "                    if row[i] == date_col:\n",
    "                        date_col_idx = i\n",
    "                    elif row[i] == value_col:\n",
    "                        value_col_idx = i\n",
    "\n",
    "                continue\n",
    "\n",
    "            value_str = row[value_col_idx]\n",
    "            if len(value_str) == 0:\n",
    "                if len(values) > 0:\n",
    "                    break\n",
    "\n",
    "                continue\n",
    "\n",
    "            dates.append(dateutil.parser.isoparse(row[date_col_idx]))\n",
    "            values.append(float(value_str))\n",
    "\n",
    "    if is_cumulative:\n",
    "        for j in range(len(values) - 1, 0, -1):\n",
    "            values[j] = values[j] - values[j - 1]\n",
    "\n",
    "    return (dates, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates, values = import_data(\"./data/household_data_60min_singleindex.csv\",\n",
    "                            \"utc_timestamp\", \"DE_KN_industrial1_grid_import\",  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_df = pd.Series(data=values, index=pd.to_datetime(dates))\n",
    "\n",
    "resolution = datetime.timedelta(minutes=1)\n",
    "start_date = datetime.datetime(2021, 1, 1)\n",
    "end_date = datetime.datetime(2021, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_csv_2_col(data, file_name):\n",
    "    with open(file_name, \"w\") as f:\n",
    "        writer = csv.writer(f, delimiter=\";\")\n",
    "        for date, value in data:\n",
    "            writer.writerow([date, value])\n",
    "\n",
    "def export_csv(data, file_name):\n",
    "    with open(file_name, \"w\") as f:\n",
    "        writer = csv.writer(f, delimiter=\";\")\n",
    "        for value in data:\n",
    "            writer.writerow([value])\n",
    "\n",
    "def transform_data(input_df, resolution, start_date, end_date):\n",
    "    assert len(input_df) >= 2, \"must provide more than two datapoints\"\n",
    "    assert resolution.seconds <= 60, \"resolutions lower than one minute not supported\"\n",
    "\n",
    "    # convert to a list of dates and corresponding values\n",
    "    input_data = []\n",
    "    for idx, value in input_df.iteritems():\n",
    "        input_data.append((idx, value))\n",
    "\n",
    "    # get resolution and time frame of input data\n",
    "    input_resolution = input_data[1][0] - input_data[0][0]\n",
    "    input_resolution_seconds = input_resolution.seconds\n",
    "    input_start_date = input_data[0][0]\n",
    "    input_end_date = input_data[-1][0]\n",
    "\n",
    "    # linearly interpolate missing values in input data\n",
    "    interp_input_data = [input_data[0], input_data[1]]\n",
    "    for i in range(2, len(input_data)):\n",
    "        prev = input_data[i - 1]\n",
    "        curr = input_data[i]\n",
    "        dist = curr[0] - prev[0]\n",
    "\n",
    "        # distance between data points is equal to resolution\n",
    "        if dist == input_resolution:\n",
    "            interp_input_data.append(curr)\n",
    "            continue\n",
    "\n",
    "        # check if distance is evenly divisible by resolution\n",
    "        rem = dist.seconds % input_resolution_seconds\n",
    "        if rem != 0:\n",
    "            raise Exception(\"inconsistent distance between data points\")\n",
    "\n",
    "        steps = math.floor(dist.seconds / input_resolution_seconds)\n",
    "        step = (curr[1] - prev[1]) / steps\n",
    "\n",
    "        for j in range(1, steps):\n",
    "            interp_input_data.append((prev[0] + (j * input_resolution), prev[1] + (j * step)))\n",
    "\n",
    "        interp_input_data.append(curr)\n",
    "\n",
    "    # transform input data to minute resolution\n",
    "    input_data_minute_res = []\n",
    "\n",
    "    if input_resolution_seconds > 60:\n",
    "        # interpolate datapoints to get minute resolution\n",
    "        interp_steps = math.floor(input_resolution_seconds / 60)\n",
    "        minute_res = datetime.timedelta(seconds=60)\n",
    "\n",
    "        for j in range(1, len(interp_input_data)):\n",
    "            prev = interp_input_data[j - 1][1]\n",
    "            curr = interp_input_data[j][1]\n",
    "            step = (curr - prev) / interp_steps\n",
    "\n",
    "            input_data_minute_res.append(interp_input_data[j - 1])\n",
    "            for k in range(1, interp_steps):\n",
    "                input_data_minute_res.append((interp_input_data[j - 1][0] + (k * minute_res), prev + (k * step)))\n",
    "\n",
    "    elif input_resolution_seconds < 60:\n",
    "        # take the average of datapoints within a minute\n",
    "        curr_sum = interp_input_data[0][1]\n",
    "        curr_cnt = 1\n",
    "\n",
    "        curr_date = interp_input_data[0][0]\n",
    "        curr_start_date = curr_date\n",
    "\n",
    "        for j in range(1, len(interp_input_data)):\n",
    "            next_date = interp_input_data[j][0]\n",
    "\n",
    "            # check if we're at the next minute\n",
    "            if next_date.minute != curr_date.minute:\n",
    "                input_data_minute_res.append((curr_start_date, curr_sum / curr_cnt))\n",
    "                curr_sum = 0\n",
    "                curr_cnt = 0\n",
    "                curr_start_date = next_date\n",
    "\n",
    "            curr_sum += interp_input_data[j][1]\n",
    "            curr_cnt += 1\n",
    "            curr_date = next_date\n",
    "\n",
    "        if curr_sum > 0:\n",
    "            input_data_minute_res.append((curr_start_date, curr_sum / curr_cnt))\n",
    "    else:\n",
    "        input_data_minute_res = interp_input_data\n",
    "\n",
    "    export_csv_2_col(input_data_minute_res, \"./input_data_minute_res.csv\")\n",
    "\n",
    "    # now calculate averages for every unique (weekday, month) pair that we have available\n",
    "    available_datapoints = dict()\n",
    "    for date, value in input_data_minute_res:\n",
    "        weekday = date.weekday()\n",
    "        month = date.month\n",
    "        key = (weekday, month)\n",
    "\n",
    "        if not key in available_datapoints:\n",
    "            available_datapoints[key] = ([0 for _ in range(0, 24 * 60)], [0 for _ in range(0, 24 * 60)])\n",
    "\n",
    "        minute_of_day = date.hour * 60 + date.minute\n",
    "        available_datapoints[key][0][minute_of_day] += value\n",
    "        available_datapoints[key][1][minute_of_day] += 1\n",
    "\n",
    "    for value in available_datapoints.values():\n",
    "        for j in range(0, len(value[0])):\n",
    "            if value[1][j] <= 1:\n",
    "                continue\n",
    "\n",
    "            value[0][j] /= value[1][j]\n",
    "\n",
    "    # uncomment to export data for all (weekday, month) pairs\n",
    "    # for key, value in available_datapoints.items():\n",
    "    #    export_csv(value[0], \"./input_data_averaged/\" + str(key[0]) + \"_\" + str(key[1]) + \".csv\")\n",
    "\n",
    "    # build the result by finding the closest (weekday, month) pair for every required day\n",
    "    result_data = []\n",
    "\n",
    "    curr_date = start_date\n",
    "    curr_day_data = None\n",
    "    prev_weekday = None\n",
    "\n",
    "    while curr_date < end_date:\n",
    "        curr_weekday = curr_date.weekday()\n",
    "        if prev_weekday is None or curr_weekday != prev_weekday:\n",
    "            curr_month = curr_date.month\n",
    "            prev_weekday = curr_weekday\n",
    "\n",
    "            if (curr_weekday, curr_month) in available_datapoints:\n",
    "                # use the available data for the day\n",
    "                curr_day_data = available_datapoints[(curr_weekday, curr_month)]\n",
    "            else:\n",
    "                # find the closest available data point\n",
    "                min_dist = math.inf\n",
    "                for key, value in available_datapoints.items():\n",
    "                    dist = abs(key[0] - curr_weekday) + abs(key[1] - curr_month)\n",
    "                    if dist >= min_dist:\n",
    "                        continue\n",
    "\n",
    "                    min_dist = dist\n",
    "                    curr_day_data = value\n",
    "\n",
    "        minute_of_day = curr_date.hour * 60 + curr_date.minute\n",
    "        result_data.append((curr_date, curr_day_data[0][minute_of_day]))\n",
    "        \n",
    "        curr_date += resolution\n",
    "\n",
    "    export_csv_2_col(result_data, \"./result.csv\")\n",
    "\n",
    "transform_data(input_df, resolution, start_date, end_date)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1604765023417",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}